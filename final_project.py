import pandas as pd
import yfinance as yf
from pmdarima import auto_arima
import matplotlib.pyplot as plt
import numpy as np
import statsmodels
from statsmodels.tsa.holtwinters import ExponentialSmoothing as ES
from sklearn.preprocessing import MinMaxScaler as MS
from keras.preprocessing.sequence import TimeseriesGenerator as TG
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM

path = r"C:\Users\jorda\OneDrive\Documents\MFinA\FINC 595 - SPC TP FInancial Time Series\NIKE Inc NYSE NKE Financials.xls"
df = yf.download(tickers=["NKE", "^GSPC"], start='2006-07-01', end='2022-03-31', parse_dates=True)['Close']

start_date = '2006-09-30'
end_date = '2022-03-31'
dates = (pd.date_range(pd.to_datetime(start_date),
                       pd.to_datetime(end_date) + pd.offsets.QuarterBegin(1), freq='Q').tolist())

income_statement = pd.read_excel(path, sheet_name="Income Statement", index_col=[0], header=[4])
income_statement.columns = dates
dep_drop = income_statement.T
dep_drop = dep_drop.drop(columns=['Depreciation & Amort.'])
income_statement = dep_drop.T

cash_flow = pd.read_excel(path, sheet_name="Cash Flow", index_col=[0], header=[4])
cash_flow.columns = dates
frame = pd.concat([income_statement, cash_flow])
frame = frame.T
frame['corporate_tax_rate'] = np.where(frame['Income Tax Expense'] > 1, frame['Income Tax Expense'] / frame['EBIT'], -1)

for index, row in frame.iterrows():
    if row['corporate_tax_rate'] > 0.40 or row['corporate_tax_rate'] < 0.10:
        frame.drop(index, inplace=True)

corporate_tax_rate = frame['corporate_tax_rate'].mean()

frame = frame.replace('-', 0)

frame['FCFF'] = frame['EBIT'] * (1-corporate_tax_rate) + frame['Depreciation & Amort.'] + frame['Capital Expenditure'] - frame['Change in Net Working Capital']

for index, row in frame.iterrows():
    if row['FCFF'] < 0:
        frame.drop(index, inplace=True)

frame['FCFF'].plot(legend=True, figsize=(12, 8))
# plt.show()

training_set = pd.DataFrame(frame['FCFF'].iloc[:42])
testing_set = pd.DataFrame(frame['FCFF'].iloc[42:])


DES_model = ES(np.asarray(training_set), trend='mul').fit()
TES_model = ES(np.asarray(training_set), trend='mul', seasonal='add', seasonal_periods=4).fit()

training_set['DES'] = DES_model.fittedvalues
training_set['TES'] = TES_model.fittedvalues

DES_forecast = DES_model.forecast(11)
testing_set['DES_Forecast'] = DES_forecast
TES_forecast = TES_model.forecast(11)
testing_set['TES_Forecast'] = TES_forecast


training_set[['FCFF', 'DES', 'TES']].plot(legend=True, figsize=(12, 8))
testing_set[['FCFF', 'DES_Forecast', 'TES_Forecast']].plot(legend=True, figsize=(12, 8))

# plt.show()

SARIMA_model = auto_arima(training_set['FCFF'], start_p=0, start_d=0, start_q=0,
                   max_p=4, max_d=4, max_q=4, seasonal=True, m=4, start_P=0, start_D=0, start_Q = 0,
                  max_P=4, max_D=4, max_Q=4, trace=True)

SARIMA_predictions = SARIMA_model.predict(n_periods=11)

fig, ax = plt.subplots(figsize=(12, 8))

ax.plot(training_set['FCFF'])
ax.plot(testing_set['FCFF'])
ax.plot(testing_set.index, SARIMA_predictions)

handles, labels = ax.get_legend_handles_labels()
fig.legend(handles, labels, loc='upper center')

# fig.show()

training_set = pd.DataFrame(frame['FCFF'].iloc[:40])
testing_set = pd.DataFrame(frame['FCFF'].iloc[40:])
print(testing_set)

scaler = MS()
scaler.fit(training_set)
train_set_scaled = scaler.transform(training_set)
test_set_scaled = scaler.transform(testing_set)

n_input = 4
n_features = 1

generator = TG(train_set_scaled, train_set_scaled, length=n_input, batch_size=1)

NN_model = Sequential()
NN_model.add(LSTM(120, activation='relu', input_shape=(n_input, n_features)))
NN_model.add(Dense(1, activation='linear'))

NN_model.compile(loss='mse', optimizer='adam')

# train the LSTM neural network on time series generated by TimeseriesGenerator
NN_model.fit(generator, epochs=150)

test_predictions_scaled = []

first_eval_batch = train_set_scaled[-4:]

first_eval_batch = first_eval_batch.reshape((1, n_input, n_features))
current_batch = first_eval_batch

for i in range(len(testing_set)):
    # predict next one time period
    current_prediction = NN_model.predict(current_batch)[0]
    test_predictions_scaled.append(current_prediction)
    # update current_batch to include 11 elements of previous batch plus current_prediction
    current_batch = np.append(current_batch[:, 1:, :], [[current_prediction]], axis=1)

# get the original time series back (inverse the MinMax Scaling)
predictions = scaler.inverse_transform(test_predictions_scaled)
'''training_set = 10**training_set
predictions = 10**predictions'''
testing_set['Predictions'] = predictions


# plot train set, test set, predictions
training_set["FCFF"].plot()
testing_set['FCFF'].plot()
testing_set['Predictions'].plot()

plt.show()
